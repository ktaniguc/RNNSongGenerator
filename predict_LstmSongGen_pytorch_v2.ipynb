{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "predict_LstmSongGen_pytorch_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktaniguc/RNNSongGenerator/blob/main/predict_LstmSongGen_pytorch_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-eJZvOwNo8R"
      },
      "source": [
        "### 使い方\n",
        "- 正しくマウント\n",
        "  ```sh\n",
        "  from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!cd \"/content/drive/MyDrive/\"\n",
        "```\n",
        "- 数セル下の以下の部分を設定\n",
        "  ```python\n",
        "  #IN/OUT/出力結果/ハイパーパラメータの名前を設定\n",
        "DIR = \"/content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/\" #モデルやら生成物やらの出力先\n",
        "model_path = DIR + \"output_model/batch20_bptt140_hid512_emb512_epoch49.pt\" #読み込むモデル\n",
        "BPM=\"120\"\n",
        "OUT_NUM = 20 #出力midi 数\n",
        "INPUT_PHRASE_NUM = 30 #予測時の入力note 数\n",
        "MEL_LENGTH = 700 #大体700でBPM=120のとき、30秒くらい\n",
        "  ```\n",
        "- あとは実行すると、predict_mid というフォルダに結果が入っています。\n",
        "\n",
        "### 更新点\n",
        "- 入力文字の数を指定できるように修正(もとは1note で固定)\n",
        "- 「予測結果のうちどれを選ぶか」の際に重み付きランダムサンプリングを選択した場合、上位何位までから選ぶかの限定ができるよう変更(明らかに突拍子のないものが出ないように)\n",
        "\n",
        "### memo\n",
        "- 出力するnote の長さ(MEL_LENGTH)は、MEL_LENGTH=700 のとき大体BPM=120で30秒くらいの感覚\n",
        "  - note のdelta_time =0 が多ければもっと短くなる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drGn9BdMhNRE"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vGtIbQFaGTk",
        "outputId": "824cd0c7-4d68-4c97-99c8-08dd9cca88c2"
      },
      "source": [
        "#!pip install tqdm\n",
        "!pip install mido keras torch\n",
        "#!pip install -U torchtext"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mido in /usr/local/lib/python3.7/dist-packages (1.2.10)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NaJr-O9HQ9R",
        "outputId": "94751f35-b988-457f-9285-3772d72d0332"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!cd \"/content/drive/MyDrive/\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqmJaCByF8uN"
      },
      "source": [
        "#IN/OUT/出力結果/ハイパーパラメータの名前を設定\n",
        "DIR = \"/content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/\" #モデルやら生成物やらの出力先\n",
        "model_path = DIR + \"output_model/batch20_bptt140_hid512_emb512_epoch49.pt\" #読み込むモデル\n",
        "BPM=\"120\"\n",
        "OUT_NUM = 20 #出力midi 数\n",
        "INPUT_PHRASE_NUM = 30 #予測時の入力note 数\n",
        "MEL_LENGTH = 700\n",
        "\n",
        "## 以降、学習時の設定によるparameters\n",
        "augment=12 #data augumentation でnote をどこまで移調するか。+1で半音。この場合+0~+11\n",
        "argstep=1 #移調のstep\n",
        "#予測した結果の出力先↓↓\n",
        "traintext_path = DIR + \"train_txt/\" #学習用データ midi をtext に変換したものを保管\n",
        "predtext_path = DIR + \"predict_txt/\"\n",
        "predmid_path = DIR + \"predict_mid/\"\n",
        "!mkdir -p {predtext_path} #予測した結果をtxt で保管\n",
        "!mkdir -p {predmid_path} #予測結果txt をmidi に変換して保管\n",
        "\n",
        "BATCH_SIZE=20 #ミニバッチサイズ\n",
        "BPTT_LEN = 140 #text とtarget の長さ\n",
        "EMBEDDING_DIM = 512 #embedding 層\n",
        "HIDDEN_DIM = 512 #隠れ層\n",
        "DROPOUT = 0.5"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8vXfAcWhQkS"
      },
      "source": [
        "## main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2falf5hk64Vr",
        "outputId": "ea0b1cc5-aac9-4213-efc2-4645cf9de6cd"
      },
      "source": [
        "#https://qiita.com/ysit/items/a601cb59523cc1961556\n",
        "#鬼のimport祭り\n",
        "import mido\n",
        "from mido import Message, MidiFile\n",
        "from pathlib import Path\n",
        "import sys, os\n",
        "import random\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as rnn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import mido\n",
        "from mido import Message, MidiFile, MidiTrack, MetaMessage\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VO-yHCvIdMW"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_S8zS6HvJiZ"
      },
      "source": [
        "#辞書を持っておくオブジェクト\n",
        "class EncoderDecoder(object):\n",
        "    def __init__(self):\n",
        "        # word_to_idの辞書\n",
        "        self.w2i = {}\n",
        "        # id_to_wordの辞書\n",
        "        self.i2w = {}\n",
        "\n",
        "    # コールされる関数\n",
        "    def __call__(self, sentence, maxlength=4000):\n",
        "        return self.transform(sentence, maxlength)\n",
        "\n",
        "    # 辞書作成\n",
        "    def make_dict(self, sentences):\n",
        "      for sentence in sentences:\n",
        "        if sentence not in self.w2i:\n",
        "          new_id = len(self.w2i)\n",
        "          self.w2i[sentence] = new_id\n",
        "          self.i2w[new_id] = sentence\n",
        "\n",
        "    # 読み込んだデータをまとめてidに変換する\n",
        "    def transform(self, sentences, maxlength=4000):\n",
        "        output = []\n",
        "        for sentence in sentences:\n",
        "            idx = self.w2i[sentence]\n",
        "            output.append(idx)\n",
        "        return output\n",
        "\n",
        "    # １文ずつ単語リストに直す\n",
        "    def decode(self, sentence):\n",
        "        return [self.i2w[id] for id in sentence if id != 0]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Bn0VK6QmjB"
      },
      "source": [
        "#データの読み込み、準備\n",
        "#print(torch.__version__)\n",
        "#chunk の辞書化\n",
        "\n",
        "class MyDataset(object):\n",
        "  \"\"\"データを(時系列長, バッチサイズ)の形状で返す\"\"\"\n",
        "\n",
        "  def __init__(self, data, batch_size, bptt_len):\n",
        "    nbatch = data.size(0) // batch_size\n",
        "    data = data.narrow(0, 0, nbatch * batch_size)\n",
        "    self.data = data.view(batch_size, -1).t().contiguous()\n",
        "    self.batch_size = batch_size\n",
        "    self.bptt_len = bptt_len\n",
        "  @classmethod\n",
        "  def splits(cls, datasets, batch_size, bptt_len):\n",
        "    ret = []\n",
        "    for data in datasets:\n",
        "      ret.append(cls(data, batch_size, bptt_len))\n",
        "    return tuple(ret)\n",
        "\n",
        "  def __len__(self):\n",
        "    return math.ceil((len(self.data) - 1 ) / self.bptt_len)\n",
        "  \n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.data) - 1, self.bptt_len):\n",
        "      seq_len = min(self.bptt_len, len(self.data) - 1 - i)\n",
        "      text = self.data[i:i + seq_len]\n",
        "      target = self.data[i + 1:i + 1 + seq_len]\n",
        "      yield text, target\n",
        "\n",
        "#データの準備\n",
        "inputTextList = Path(traintext_path).glob('**/*.txt')\n",
        "mididata = []\n",
        "maxlength = 0\n",
        "for inputText in inputTextList:\n",
        "  f = open(inputText, 'r')\n",
        "  texts = f.read()\n",
        "  text = texts.split(\",\")\n",
        "  text.pop(-1)\n",
        "  mididata = mididata + text\n",
        "  if len(mididata) > maxlength:\n",
        "    maxlength = len(text)\n",
        "encTool = EncoderDecoder()\n",
        "encTool.make_dict(mididata)\n",
        "data_id = encTool(mididata, maxlength=maxlength)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X07IyA7cXJ6"
      },
      "source": [
        "#ネットの定義\n",
        "#ネットの定義\n",
        "class RNNLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, h_dim, dropout):\n",
        "        '''\n",
        "        vocab_size:語彙の数\n",
        "        emb_dim:埋め込みベクトルの次元\n",
        "        h_dim:隠れ層の次元\n",
        "        dropout: ドロップアウトの確率\n",
        "        '''\n",
        "        super(RNNLM, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "        self.lstm1 = nn.LSTM(emb_dim, h_dim)\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "        self.lstm2 = nn.LSTM(h_dim, h_dim)\n",
        "        self.drop3 = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(h_dim, vocab_size)\n",
        "\n",
        "        # 重みを初期化\n",
        "        #他にも色々方法はある https://pytorch.org/docs/stable/nn.init.html\n",
        "        nn.init.normal_(self.embed.weight, std=0.01)\n",
        "        nn.init.normal_(self.lstm1.weight_ih_l0, std=1/math.sqrt(emb_dim))\n",
        "        nn.init.normal_(self.lstm1.weight_hh_l0, std=1/math.sqrt(h_dim))\n",
        "        nn.init.zeros_(self.lstm1.bias_ih_l0)\n",
        "        nn.init.zeros_(self.lstm1.bias_hh_l0)\n",
        "        nn.init.normal_(self.lstm2.weight_ih_l0, std=1/math.sqrt(emb_dim))\n",
        "        nn.init.normal_(self.lstm2.weight_hh_l0, std=1/math.sqrt(h_dim))\n",
        "        nn.init.zeros_(self.lstm2.bias_ih_l0)\n",
        "        nn.init.zeros_(self.lstm2.bias_hh_l0)\n",
        "        self.linear.weight = self.embed.weight  # 重み共有\n",
        "        nn.init.zeros_(self.linear.bias)\n",
        "\n",
        "    def forward(self, sentence, hidden1_prev, hidden2_prev):\n",
        "        emb = self.embed(sentence)\n",
        "        emb = self.drop1(emb)\n",
        "        lstm1_out, hidden1_next = self.lstm1(emb, hidden1_prev)\n",
        "        lstm1_out = self.drop2(lstm1_out)\n",
        "        lstm2_out, hidden2_next = self.lstm2(lstm1_out, hidden2_prev)\n",
        "        lstm2_out = self.drop3(lstm2_out)\n",
        "        out = self.linear(lstm2_out)\n",
        "        #hidden_next:隠れ状態と記憶セルのセル状態を含んだタプル\n",
        "        return out, hidden1_next, hidden2_next"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VymoqSZIXkU",
        "outputId": "7dc73dc5-6c20-493a-9560-245368a1a193"
      },
      "source": [
        "#DS = os.sep\n",
        "#bs = os.path.dirname(__file__) + DS\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = torch.device(\"cpu\")\n",
        "VOCAB_SIZE = len(encTool.i2w)\n",
        "#モデル生成\n",
        "print('read model...')\n",
        "model = RNNLM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, DROPOUT).to(device)\n",
        "modelname = torch.load(model_path)\n",
        "model.load_state_dict(modelname, strict=False)\n",
        "\n",
        "def make_melody(model, start_ids, length=400, skip_ids=None, prob=True, seed=2021, batch_size=1, top=None):\n",
        "  '''\n",
        "  args:\n",
        "  model:入力モデル\n",
        "  start_ids:最初の入力となるnote のid\n",
        "  length:出力長\n",
        "  prob:確率的に予測結果を選択するか否か\n",
        "  seed:prob=True のときのランダムシード\n",
        "  '''\n",
        "  word_ids = []\n",
        "  word_ids += start_ids\n",
        "  model.eval() #BatchNorm やdropout をOFF\n",
        "  #勾配の自動計算防止\n",
        "  with torch.no_grad():\n",
        "    input_id = start_ids\n",
        "    hidden1, hidden2 = None, None\n",
        "    while len(word_ids) < length:\n",
        "      input = torch.tensor(input_id, dtype=torch.long,\n",
        "                          device=device).view(1, -1).t().contiguous()\n",
        "      #input = torch.tensor(input_id, device=device)\n",
        "      output, hidden1, hidden2 = model(input, hidden1, hidden2)\n",
        "      #output, hidden = model(input)\n",
        "      # outputは(時系列長, バッチサイズ=1, 語彙数)\n",
        "      p_list = F.softmax(output[-1].flatten(), dim=0)\n",
        "      if top is not None:\n",
        "        sorted_p_list = p_list.sort(descending=True).values[:top]\n",
        "        sorted_idx = p_list.sort(descending=True).indices[:top]\n",
        "        p_list = sorted_p_list / sorted_p_list.sum()\n",
        "      # 確率的に選択(重み付きランダムサンプリング)\n",
        "      if prob:\n",
        "        while True:\n",
        "          rnd = random.random()\n",
        "          p_sum = 0\n",
        "          for idx, p in enumerate(p_list):\n",
        "            p_sum += p.item()\n",
        "            if rnd < p_sum:\n",
        "              sampled = idx if top is None else sorted_idx[idx].item()\n",
        "              break\n",
        "          # skip_idsに含まれる時はやり直し\n",
        "          if (skip_ids is None) or (sampled not in skip_ids):\n",
        "            break\n",
        "      # 決定的に選択\n",
        "      else:\n",
        "        if skip_ids is not None:\n",
        "          p_list[skip_ids] = 0\n",
        "        sampled = p_list.argmax().item()\n",
        "\n",
        "      word_ids.append(sampled)\n",
        "      input_id = sampled\n",
        "  return word_ids\n",
        "\n",
        "print(\"start generating melody....\")\n",
        "for i_out in range(0, OUT_NUM):\n",
        "  start_ids=[]\n",
        "  start_id = random.randint(0, len(data_id)-INPUT_PHRASE_NUM)\n",
        "  start_ids = data_id[start_id:start_id + INPUT_PHRASE_NUM]\n",
        "  word_ids = make_melody(model, start_ids, length=MEL_LENGTH, batch_size = BATCH_SIZE, prob=True, top=100)\n",
        "  text = ','.join(encTool.decode(word_ids))\n",
        "  resultTextName = predtext_path + \"out{}_batch{}_embed{}.txt\".format(i_out, BATCH_SIZE, EMBEDDING_DIM)\n",
        "  file = open(resultTextName,'w+',encoding='utf-8').write(text)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read model...\n",
            "start generating melody....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg3c8ndLJWoj"
      },
      "source": [
        "chunk2midi.py "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RUc-P57JjuN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6165cb4-ba65-4a68-bfb6-ba3de96ef62d"
      },
      "source": [
        "def num2note_on_off(num):\n",
        "  if int(num, 10) == 1:\n",
        "    return \"note_on\"\n",
        "  else:\n",
        "    return \"note_off\"\n",
        "\n",
        "#args = sys.argv \n",
        "resultTextList = Path(predtext_path).glob('**/*.txt')\n",
        "for resultTextName in tqdm(resultTextList):\n",
        "  print(\"converting : \", resultTextName)\n",
        "  f = open(resultTextName, 'r')\n",
        "  data = f.read()\n",
        "  data_per_sound = data.split(\",\")\n",
        "  textName = os.path.split(resultTextName)[1].replace(\".txt\", \"\")\n",
        "  outputMidName = predmid_path + textName + \".mid\"\n",
        "  #type(note_on=1, note_off=0)_note_velocity_time\n",
        "  mid = MidiFile()\n",
        "  track = MidiTrack()\n",
        "  mid.tracks.append(track)\n",
        "  bpm = int(BPM)\n",
        "  track.append(MetaMessage('set_tempo', tempo=mido.bpm2tempo(bpm)))\n",
        "  for i_data in data_per_sound:\n",
        "    #print(i_data)\n",
        "    if i_data == \"\":\n",
        "      continue\n",
        "    parts = i_data.split(\"_\")\n",
        "    if len(parts) != 4 or int(parts[0], 10) > 1:\n",
        "      continue\n",
        "    if parts[3] == \"\":\n",
        "      continue\n",
        "    if int(parts[2]) > 127:\n",
        "      continue\n",
        "    track.append(Message(num2note_on_off(parts[0]), note=int(parts[1], 10), velocity=int(parts[2], 10), time=int(parts[3], 10)))\n",
        "\n",
        "  mid.save(outputMidName)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6it [00:00, 52.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out0_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out1_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out2_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out3_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out4_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out5_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out6_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out7_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out8_batch20_embed512.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "18it [00:00, 47.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out9_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out10_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out11_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out12_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out13_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out14_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out15_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out16_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out17_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out18_batch20_embed512.txt\n",
            "converting :  /content/drive/MyDrive/Colab_Notebooks/dev_Aug2021_pytorch_v5/predict_txt/out19_batch20_embed512.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r20it [00:00, 47.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}